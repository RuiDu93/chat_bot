{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todo 效果可能不好的原因：\n",
    "* 特征没有提取好：分词部分、停词的问题?字典的问题?卡方检验的参数设置?\n",
    "* 模型本身的问题（vsm的锅？）\n",
    "* 数据量是否足够?\n",
    "* tf-idf的问题?嗯..似乎频次都是1,暂时没有tf-idf需求吧?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\59256\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.677 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 生成vsm词袋模型\n",
    "bag_of_words ={}\n",
    "text_list =[]\n",
    "_label = []\n",
    "\n",
    "search_pd = pd.read_csv('./search.csv' ,header= -1)\n",
    "# todo 技术方案不好的原因...?\n",
    "for s in search_pd.iterrows():\n",
    "    seg_list = jieba.lcut(s[1][0], cut_all=False)\n",
    "    text_list.append(seg_list)\n",
    "    _label.append(0)\n",
    "    for seg in seg_list:\n",
    "        if seg not in bag_of_words:\n",
    "            bag_of_words[seg] = 1\n",
    "        else:\n",
    "            bag_of_words[seg] += 1\n",
    "\n",
    "pub_pd = pd.read_csv('./pub.csv' ,header= -1)\n",
    "for s in pub_pd.iterrows():\n",
    "    seg_list = jieba.lcut(s[1][0], cut_all=False)\n",
    "    text_list.append(seg_list)\n",
    "    _label.append(1)\n",
    "    for seg in seg_list:\n",
    "        if seg not in bag_of_words:\n",
    "            bag_of_words[seg] = 1\n",
    "        else:\n",
    "            bag_of_words[seg] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vsm_vec = {}\n",
    "row_vsm_vec = []\n",
    "count = 0\n",
    "for key,value in bag_of_words.items():\n",
    "    sub_dic = {}\n",
    "    \n",
    "    # 其他的信息,比如重要性,tf-idf值之类的信息也保存再这里\n",
    "    sub_dic['index'] = count\n",
    "    count += 1\n",
    "    vsm_vec[key] = sub_dic\n",
    "    \n",
    "    row_vsm_vec.append(key)\n",
    "    \n",
    "    sub_dic['count'] = value\n",
    "    # todo 增加 tf-idf的值!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成向量\n",
    "vec_col_count = len(vsm_vec)\n",
    "_list = []\n",
    "\n",
    "for l in text_list:\n",
    "    self_bag = {}\n",
    "    row_vec = [0]*vec_col_count\n",
    "    for wd in l:\n",
    "        if wd in self_bag:\n",
    "            self_bag[wd] += 1\n",
    "        else:\n",
    "            self_bag[wd] = 1\n",
    "    for b,c in self_bag.items():\n",
    "        if b in vsm_vec:\n",
    "            row_vec[vsm_vec[b]['index']] = c\n",
    "    _list.append(row_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 卡方检验得到有效特征\n",
    "chi2 = SelectKBest(chi2,k=60).fit(_list, _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 输出rank的score！！\n",
    "top = 100\n",
    "\n",
    "f_ip = {}\n",
    "for col_index in range(0,vec_col_count):\n",
    "    f_ip[col_index] = chi2.scores_[col_index]\n",
    "\n",
    "items = f_ip.items()\n",
    "it = sorted(items,key=lambda d:d[1], reverse = True)\n",
    "f_ip_array = []\n",
    "\n",
    "for key,value in it:\n",
    "    f_ip_array.append(key)\n",
    "\n",
    "f_ip_array = f_ip_array[0:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chi2_vsm_vec = {}\n",
    "\n",
    "chi2_count = 0\n",
    "for col_index in f_ip_array:\n",
    "    dic = vsm_vec[row_vsm_vec[col_index]]\n",
    "    dic['index'] = chi2_count\n",
    "    chi2_count += 1\n",
    "    chi2_vsm_vec[row_vsm_vec[col_index]] = dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成向量\n",
    "chi2_vec_col_count = len(chi2_vsm_vec)\n",
    "_chi2_list = []\n",
    "\n",
    "\n",
    "for l in text_list:\n",
    "    self_bag = {}\n",
    "    row_vec = [0]*chi2_vec_col_count\n",
    "    for wd in l:\n",
    "        if wd in self_bag:\n",
    "            self_bag[wd] += 1\n",
    "        else:\n",
    "            self_bag[wd] = 1\n",
    "    for b,c in self_bag.items():\n",
    "        if b in chi2_vsm_vec:\n",
    "            row_vec[chi2_vsm_vec[b]['index']] = c\n",
    "    _chi2_list.append(row_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97169811320754718"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=40,oob_score= True)\n",
    "clf = clf.fit(_chi2_list, _label)\n",
    "\n",
    "# 用随机森林做~ 嗯...为什么呢...\n",
    "clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_model.m']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存相关参数~\n",
    "chi2_vsm_vec\n",
    "with open('./chi2_vsm_vec','wb') as f:\n",
    "    pickle.dump(chi2_vsm_vec,f)\n",
    "joblib.dump(clf, \"train_model.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 预测流程~\n",
    "\n",
    "txt = ['找一下水杯的图片','发个话题吧!','我要发一个话题','来一张长城的图片','来张壁纸','百度搜图','hi! 我要搜图']\n",
    "\n",
    "# 加载模型~\n",
    "with open('./chi2_vsm_vec','rb') as f:\n",
    "    n_chi2_vsm_vec = pickle.load(f)\n",
    "rf_clf = joblib.load('./train_model.m')\n",
    "\n",
    "\n",
    "for t in txt:\n",
    "    seg_list = jieba.lcut(t, cut_all=False)\n",
    "\n",
    "    # 生成向量\n",
    "    chi2_vec_col_count = len(n_chi2_vsm_vec)\n",
    "    _chi2_list = []\n",
    "\n",
    "    l = seg_list\n",
    "\n",
    "    self_bag = {}\n",
    "    row_vec = [0]*chi2_vec_col_count\n",
    "    for wd in l:\n",
    "        if wd in self_bag:\n",
    "            self_bag[wd] += 1\n",
    "        else:\n",
    "            self_bag[wd] = 1\n",
    "    for b,c in self_bag.items():\n",
    "        if b in n_chi2_vsm_vec:\n",
    "            row_vec[n_chi2_vsm_vec[b]['index']] = c\n",
    "\n",
    "    print(rf_clf.predict([row_vec]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
